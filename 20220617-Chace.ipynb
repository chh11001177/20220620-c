{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df875bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U fake_useragent\n",
    "from requests import session\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "from fake_useragent import UserAgent\n",
    "from lxml import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea8bebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##以Dcard API V2 爬取。存成json\n",
    "\n",
    "def search_article(corp = '饗賓集團', brand = '饗饗'):\n",
    "    \n",
    "    ua = UserAgent(use_cache_server=False)\n",
    "    user_agent = ua.random\n",
    "    headers = {'user-agent': user_agent}\n",
    "    s = session()\n",
    "    \n",
    "    api = 'https://www.dcard.tw/service/api/v2'\n",
    "    url = api + '/search?forum=food&query='+ brand\n",
    "\n",
    "    res = s.get(url, headers = headers)\n",
    "    html = res.text\n",
    "    rejs = json.loads(html)\n",
    "\n",
    "    final_art = []\n",
    "    #存取文章\n",
    "    for i in rejs:\n",
    "        a = {}\n",
    "        a['Corp'] = corp\n",
    "        a['Brand'] = brand\n",
    "        a['Platform'] = \"Dcard\"\n",
    "        a['Branch'] = \"\"\n",
    "        a['Username'] = i['memberId']\n",
    "        a['ReviewTime'] = i['createdAt'][0:10]\n",
    "        a['Title'] = i['title']\n",
    "        a['ReviewContent'] = i['excerpt']\n",
    "        a['ReviewStar'] = \"\"\n",
    "        a['commentCount'] = i['commentCount']\n",
    "        final_art.append(a)\n",
    "        \n",
    "        #爬回文資訊\n",
    "        url2 = api+ '/posts/'+ str(i['id']) + '/comments'\n",
    "        res2 = s.get(url2, headers = headers)\n",
    "        html2 = res2.text\n",
    "        CmntsData = json.loads(html2)\n",
    "        \n",
    "        comment_content = []\n",
    "        print('正在爬這篇文章', i['title'])\n",
    "        time.sleep(random.randint(1,5))\n",
    "        for j in CmntsData:\n",
    "            try:\n",
    "                b = {}\n",
    "                b['Corp'] = corp\n",
    "                b['Brand'] = brand\n",
    "                b['Platform'] = \"Dcard\"\n",
    "                b['Branch'] = \"\"\n",
    "                b['Username'] = j['id']\n",
    "                b['ReviewTime'] = j['createdAt'][0:10]\n",
    "                b['Title'] = i['title']\n",
    "                b['ReviewContent'] = j['content']\n",
    "                b['ReviewStar'] = \"\"\n",
    "                b['commentCount'] = \"\"\n",
    "                comment_content.append(b)\n",
    "                print('正爬到第', j['floor'], '樓')\n",
    "                time.sleep(random.randint(1,3))\n",
    "            except KeyError:\n",
    "                print('留言被刪除')\n",
    "                continue\n",
    "   \n",
    "        for i in comment_content:\n",
    "            final_art.append(i)\n",
    "            \n",
    "    return final_art\n",
    "\n",
    "\n",
    "def output(filename, data):\n",
    "    try:\n",
    "        with open(filename +\".json\", 'wb+') as f:\n",
    "            f.write(json.dumps(data, indent=1, ensure_ascii=False).encode('utf-8'))\n",
    "            print('爬取完成', filename + '.json', '輸出成功')\n",
    "    except Exception as err:\n",
    "        print(filename +'.json', '輸出失敗')\n",
    "        print('error message:', err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505138ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立字典與陣列以便做迴圈\n",
    "\n",
    "dict1= {'饗賓集團':['饗饗','旭集','饗泰多','饗食天堂','果然匯','小福利火鍋','開飯川食堂','真珠'],\n",
    "        '王品集團':['12mini','丰禾','王品','石二鍋','肉次方','西提','尬鍋','享鴨','和牛涮','青花驕','品田牧場','原燒','夏慕尼','莆田','陶板屋','最肉燒肉','聚北海道鍋物','藝奇','hot7','the wang']}\n",
    "corp1 = '饗賓集團'\n",
    "corp2 = '王品集團'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5757c4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#饗賓迴圈執行完 接著執行王品迴圈\n",
    "for a in range(0,len(dict1[corp1])):\n",
    "    data = search_article(corp = corp1, brand = dict1[corp1][a])\n",
    "    output(dict1[corp1][a], data)\n",
    "\n",
    "#    \n",
    "for a in range(0,len(dict1[corp2])):\n",
    "    data = search_article(corp = corp2, brand = dict1[corp2][a])\n",
    "    output(dict1[corp2][a], data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1536f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "## json to csv\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "for b in range(0,len(dict1[corp1])):\n",
    "    with open(dict1[corp1][b]+'.json', 'r', encoding = \"utf-8\") as f:\n",
    "        a = json.loads(f.read())\n",
    "\n",
    "        df = pd.json_normalize(a)\n",
    "        df.to_csv('Dcard_'+dict1[corp1][b]+'.csv', encoding='utf-8-sig', index=False)\n",
    "\n",
    "for b in range(0,len(dict1[corp2])):\n",
    "    with open(dict1[corp2][b]+'.json', encoding = \"utf-8\") as f:\n",
    "        a = json.loads(f.read())\n",
    "\n",
    "        df = pd.json_normalize(a)\n",
    "        df.to_csv('Dcard_'+dict1[corp2][b]+'.csv', encoding='utf-8-sig', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de2c18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##合併所有 Dard_ 開頭的csv檔案。存成concatted7_final.csv，不要index，並且以utf-8-sig編碼\n",
    "\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    " \n",
    "files = glob('Dcard_*.csv')\n",
    "df2 = pd.concat((pd.read_csv(file) for file in files), ignore_index=True)\n",
    "df2.to_csv( 'concatted7_final.csv', index=False, encoding=\"utf-8-sig\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e120197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dcard_饗饗_new.csv存取完成\n",
      "dcard_旭集_new.csv存取完成\n",
      "dcard_饗泰多_new.csv存取完成\n",
      "dcard_饗食天堂_new.csv存取完成\n",
      "dcard_果然匯_new.csv存取完成\n",
      "dcard_小福利火鍋_new.csv存取完成\n",
      "dcard_開飯川食堂_new.csv存取完成\n",
      "dcard_真珠_new.csv存取完成\n",
      "dcard_12mini_new.csv存取完成\n",
      "dcard_丰禾_new.csv存取完成\n",
      "dcard_王品_new.csv存取完成\n",
      "dcard_石二鍋_new.csv存取完成\n",
      "dcard_肉次方_new.csv存取完成\n",
      "dcard_西提_new.csv存取完成\n",
      "dcard_尬鍋_new.csv存取完成\n",
      "dcard_享鴨_new.csv存取完成\n",
      "dcard_和牛涮_new.csv存取完成\n",
      "dcard_青花驕_new.csv存取完成\n",
      "dcard_品田牧場_new.csv存取完成\n",
      "dcard_原燒_new.csv存取完成\n",
      "dcard_夏慕尼_new.csv存取完成\n",
      "dcard_莆田_new.csv存取完成\n",
      "dcard_陶板屋_new.csv存取完成\n",
      "dcard_最肉燒肉_new.csv存取完成\n",
      "dcard_聚北海道鍋物_new.csv存取完成\n",
      "dcard_藝奇_new.csv存取完成\n",
      "dcard_hot7_new.csv存取完成\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m brandname1 \u001b[38;5;129;01min\u001b[39;00m alist:\n\u001b[1;32m      6\u001b[0m     files \u001b[38;5;241m=\u001b[39m glob(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDcard_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(brandname1)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     df1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     df1\u001b[38;5;241m.\u001b[39mto_csv( \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdcard_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(brandname1)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_new.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8-sig\u001b[39m\u001b[38;5;124m\"\u001b[39m )\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdcard_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(brandname1)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_new.csv存取完成\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py:347\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[1;32m    145\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[Hashable, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    154\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    155\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m    along the other axes.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03m    ValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/concat.py:404\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    401\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 404\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "#有留言換行問題的通通丟進來重新存一次，再用Tableau看才ＯＫ\n",
    "\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    " \n",
    "alist=['饗饗','旭集','饗泰多','饗食天堂','果然匯','小福利火鍋','開飯川食堂','真珠','12mini','丰禾','王品','石二鍋','肉次方','西提','尬鍋','享鴨','和牛涮','青花驕','品田牧場','原燒','夏慕尼','莆田','陶板屋','最肉燒肉','聚北海道鍋物','藝奇','hot7','thewang']\n",
    "    \n",
    "for brandname1 in alist:\n",
    "    files = glob('Dcard_'+str(brandname1)+'.csv')\n",
    "    df1 = pd.concat((pd.read_csv(file) for file in files), ignore_index=True)\n",
    "    df1.to_csv( 'dcard_'+str(brandname1)+'_new.csv', index=False, encoding=\"utf-8-sig\" )\n",
    "    print ('dcard_'+str(brandname1)+'_new.csv存取完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb8b6550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/42/7l02yz4j6vggnl38lsbgsv4r0000gn/T/ipykernel_31565/1026784621.py:5: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.concat((pd.read_csv(file) for file in files), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    " \n",
    "files = glob('concatted6_*.csv')\n",
    "df2 = pd.concat((pd.read_csv(file) for file in files), ignore_index=True)\n",
    "df2.to_csv( 'concatted7_final.csv', index=False, encoding=\"utf-8-sig\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57a9ac58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corp</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Branch</th>\n",
       "      <th>Username</th>\n",
       "      <th>ReviewTime</th>\n",
       "      <th>Title</th>\n",
       "      <th>ReviewContent</th>\n",
       "      <th>ReviewStar</th>\n",
       "      <th>CommentCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>王品集團</td>\n",
       "      <td>王品牛排</td>\n",
       "      <td>GoogleReviews</td>\n",
       "      <td>台北羅斯福店</td>\n",
       "      <td>april Chou</td>\n",
       "      <td>2022/5/13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>王品集團</td>\n",
       "      <td>王品牛排</td>\n",
       "      <td>GoogleReviews</td>\n",
       "      <td>台北羅斯福店</td>\n",
       "      <td>Ricky Lee (朣言童語)</td>\n",
       "      <td>2022/5/13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>大概十年吃一次…..</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>王品集團</td>\n",
       "      <td>王品牛排</td>\n",
       "      <td>GoogleReviews</td>\n",
       "      <td>台北羅斯福店</td>\n",
       "      <td>LiLi</td>\n",
       "      <td>2022/5/13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>車程五分鐘，外帶所有餐點都冷掉了，非常影響食慾cp值低</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>王品集團</td>\n",
       "      <td>王品牛排</td>\n",
       "      <td>GoogleReviews</td>\n",
       "      <td>台北羅斯福店</td>\n",
       "      <td>克羅諾</td>\n",
       "      <td>2022/5/6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>王品集團</td>\n",
       "      <td>王品牛排</td>\n",
       "      <td>GoogleReviews</td>\n",
       "      <td>台北羅斯福店</td>\n",
       "      <td>AJ ahn</td>\n",
       "      <td>2022/5/6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(由 Google 提供翻譯) 好吃??\\n\\n(原始評論)\\n好吃??</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261812</th>\n",
       "      <td>饗賓集團</td>\n",
       "      <td>果然匯</td>\n",
       "      <td>Ptt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patric1224</td>\n",
       "      <td>2021/11/1</td>\n",
       "      <td>[問卦] 果然匯要吃什麼比較內行？</td>\n",
       "      <td>素食吃到飽根本就是一般素食拿掉肉，</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261813</th>\n",
       "      <td>饗賓集團</td>\n",
       "      <td>果然匯</td>\n",
       "      <td>Ptt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patric1224</td>\n",
       "      <td>2021/11/1</td>\n",
       "      <td>[問卦] 果然匯要吃什麼比較內行？</td>\n",
       "      <td>並沒有比較好吃或特別。</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261814</th>\n",
       "      <td>饗賓集團</td>\n",
       "      <td>果然匯</td>\n",
       "      <td>Ptt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>patric1224</td>\n",
       "      <td>2021/11/1</td>\n",
       "      <td>[問卦] 果然匯要吃什麼比較內行？</td>\n",
       "      <td>更正,一般吃到飽拿掉肉。</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261815</th>\n",
       "      <td>饗賓集團</td>\n",
       "      <td>果然匯</td>\n",
       "      <td>Ptt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GossipCandy</td>\n",
       "      <td>2021/11/1</td>\n",
       "      <td>[問卦] 果然匯要吃什麼比較內行？</td>\n",
       "      <td>松露奶油燉飯好ㄘ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261816</th>\n",
       "      <td>饗賓集團</td>\n",
       "      <td>果然匯</td>\n",
       "      <td>Ptt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ffreakk</td>\n",
       "      <td>2021/11/2</td>\n",
       "      <td>[問卦] 果然匯要吃什麼比較內行？</td>\n",
       "      <td>辣根醬洋芋沙拉 印象中這個最好吃</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261817 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Corp Brand       Platform  Branch          Username ReviewTime  \\\n",
       "0       王品集團  王品牛排  GoogleReviews  台北羅斯福店        april Chou  2022/5/13   \n",
       "1       王品集團  王品牛排  GoogleReviews  台北羅斯福店  Ricky Lee (朣言童語)  2022/5/13   \n",
       "2       王品集團  王品牛排  GoogleReviews  台北羅斯福店              LiLi  2022/5/13   \n",
       "3       王品集團  王品牛排  GoogleReviews  台北羅斯福店               克羅諾   2022/5/6   \n",
       "4       王品集團  王品牛排  GoogleReviews  台北羅斯福店            AJ ahn   2022/5/6   \n",
       "...      ...   ...            ...     ...               ...        ...   \n",
       "261812  饗賓集團   果然匯            Ptt     NaN        patric1224  2021/11/1   \n",
       "261813  饗賓集團   果然匯            Ptt     NaN        patric1224  2021/11/1   \n",
       "261814  饗賓集團   果然匯            Ptt     NaN        patric1224  2021/11/1   \n",
       "261815  饗賓集團   果然匯            Ptt     NaN       GossipCandy  2021/11/1   \n",
       "261816  饗賓集團   果然匯            Ptt     NaN           ffreakk  2021/11/2   \n",
       "\n",
       "                    Title                         ReviewContent  ReviewStar  \\\n",
       "0                     NaN                                   NaN         5.0   \n",
       "1                     NaN                            大概十年吃一次…..         4.0   \n",
       "2                     NaN           車程五分鐘，外帶所有餐點都冷掉了，非常影響食慾cp值低         1.0   \n",
       "3                     NaN                                   NaN         4.0   \n",
       "4                     NaN  (由 Google 提供翻譯) 好吃??\\n\\n(原始評論)\\n好吃??         4.0   \n",
       "...                   ...                                   ...         ...   \n",
       "261812  [問卦] 果然匯要吃什麼比較內行？                     素食吃到飽根本就是一般素食拿掉肉，         NaN   \n",
       "261813  [問卦] 果然匯要吃什麼比較內行？                           並沒有比較好吃或特別。         NaN   \n",
       "261814  [問卦] 果然匯要吃什麼比較內行？                          更正,一般吃到飽拿掉肉。         NaN   \n",
       "261815  [問卦] 果然匯要吃什麼比較內行？                              松露奶油燉飯好ㄘ         NaN   \n",
       "261816  [問卦] 果然匯要吃什麼比較內行？                      辣根醬洋芋沙拉 印象中這個最好吃         NaN   \n",
       "\n",
       "        CommentCount  \n",
       "0                NaN  \n",
       "1                NaN  \n",
       "2                NaN  \n",
       "3                NaN  \n",
       "4                NaN  \n",
       "...              ...  \n",
       "261812           NaN  \n",
       "261813           NaN  \n",
       "261814           NaN  \n",
       "261815           NaN  \n",
       "261816           NaN  \n",
       "\n",
       "[261817 rows x 10 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb3d871",
   "metadata": {},
   "outputs": [],
   "source": [
    "##martin提供\n",
    "\n",
    "import random\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager  # 自動更新webdriver pip install webdriver-manager\n",
    "import time\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "search = \"王品\"\n",
    "ua = UserAgent()\n",
    "options = Options()\n",
    "options.add_argument(\"user-agent=\" + ua.chrome)\n",
    "# options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n",
    "driver.get(\"https://www.dcard.tw/search?forum=food&query={}\".format(search))\n",
    "\n",
    "temp_height = 0\n",
    "link_list = []\n",
    "while True:\n",
    "    driver.execute_script(\"window.scrollBy(0,1000)\")\n",
    "    time.sleep(random.randint(5, 15))\n",
    "    check_height = driver.execute_script(\"return document.documentElement.scrollTop || window.pageYOffset || document.body.scrollTop;\")\n",
    "    if check_height == temp_height:\n",
    "        break\n",
    "    temp_height = check_height\n",
    "driver.quit()\n",
    "\n",
    "soup = bs(driver.page_source, 'lxml')\n",
    "url = soup.find_all('a', class_=\"sc-b205d8ae-3 iOQsOu\")\n",
    "link_list.append(\"https://www.dcard.tw\" + url.get(\"href\"))\n",
    "\n",
    "dic = {}\n",
    "dic[\"link\"] = link_list\n",
    "ls = []\n",
    "ls.append(dic)\n",
    "with open(\"link.json\",\"r\",encoding=\"utf-8\") as file:\n",
    "    json.dump(ls, file, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
